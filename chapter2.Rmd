---
title       : Logistic regression
description : Regression for binary outcomes, training and testing a (predictive) model, cross-validation

--- type:NormalExercise lang:r xp:100 skills:1 key:f8515d62e1
## Two more datasets

Welcome to the *Logistic regression* chapter.

During the next exercises, we will be combining, wrangling and analysing two new data sets retrieved from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets.html), a great source for open data. 

The data are from two identical questionaires related to secondary school student alcohol comsumption in Portugal. Read about the data and the variables [here](https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION).

R offers the convenient `paste()` function which makes it easy to combine characters. Let's utilize it to get our hands on the data!

*** =instructions
- Create and print out the object `url_math' 
- Adjust the code: Make `url_math` into a valid web address.
- Create object `math` by reading the math class questionaire data from the web address defined in `url_math`.
- Create object `url_por` similarily to `url_math`, using the `url` object.
- Create object `por` by reading the portuguese class questionaire data from the web address defined in `url_por`.
- Print out the names of the columns in both data sets.

*** =hint
- hint

*** =pre_exercise_code
```{r}
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets"
```

*** =sample_code
```{r}
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets"

# web address for math class data
url_math <- paste(url, "student-mat.csv", sep = " !!!CHANGE ME!!! ")
url_math

# read the math class questionaire data into memory
math <- read.table(url_math, sep = ";" , header=TRUE)

# web address for portuguese class data
url_por <- paste("replace me!", "student-por.csv", sep ="/")

## read the portuguese class questionaire data into memory
por <- read.table(url_por, sep = ";", header = TRUE)

## look at the column names of both data
colnames(math)


```

*** =solution
```{r}
url <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets"

# web address for math class data
url_math <- paste(url, "student-mat.csv", sep = "/")
url_math

# read the math class questionaire data into memory
math <- read.table(url_math, sep = ";" , header=TRUE)

# web address for portuguese class data
url_por <- paste(url, "student-por.csv", sep ="/")

## read the portuguese class questionaire data into memory
por <- read.table(url_por, sep = ";", header = TRUE)

## look at the column names of both data
colnames(math)
colnames(por)

```

*** =sct
```{r}

test_object("url_math", incorrect_msg = "Make the necessary changes to store a valid web address in the `url_math` object")
test_object("math", incorrect_msg = "Use `url_math` to load data and store the data in the `math` object.")

test_object("url_por", incorrect_msg = "Make the necessary changes to store a valid web address in the `url_por` object")
test_object("por", incorrect_msg = "Use `url_por` to load data and store the data in the `por` object.")

test_output_contains("colnames(math)", times = 2, incorrect_msg = "Please print out the column names of both data sets")

test_error()
success_msg("Nice work! That was a tough warm-up!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:af9b851a1c
## Joining two datasets

There are multiple students who have answered both questionaires in our two datasets. Unfortunately we do not have a single identification variable to identify these students. However, we can use a bunch of background questions together for identification.

Combining two data sets is easy if the data have a mutual identifier column or if a combination of mutual columns can be used as identifiers. 

Here we'll use `inner.join()` function from the dplyr library to combine the data (remember the [dplyr cheatsheet!](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)). This means that we'll only keep the students who answered the questionaire in both math and portuguese classes.

*** =instructions
- Access the dplyr library and create object `join_by`.
- Adjust the code: define the argument `by` of `inner_join()` to join the `math` and `por` data frames by the columns defined in `join_by`.
- Print out the column names of the joined data set.
- Adjust the code: add the argument 'suffix' to `inner_join()` and give it the vector of two  characters: ".math" and ".por". Do the `inner_join()` again and print out the new column names again.
- Use the `glimpse()` function from 'dplyr' to look at the joined data. Which data types are present?

*** =hint
- hint

*** =pre_exercise_code
```{r}
## read the math class questionaire data
math <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-mat.csv",sep=";",header=TRUE)

## read the portuguese class questionaire data
por <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-por.csv",sep=";",header=TRUE)

```

*** =sample_code
```{r}
# math and por are available

# access the dplyr library
library(dplyr)

# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")

# join the two datasets by the selected identifiers
math_por <- inner_join(math, por, by = "change me!")

# see the new column names and glimpse at the data


```

*** =solution
```{r}
# math and por are available

# access the dplyr library
library(dplyr)

# common columns to use as identifiers
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")

# join the two datasets by the selected identifiers
math_por <- inner_join(math, por, by = join_by, suffix = c(".math", ".por"))

## see the new column names and glimpse at the data
colnames(math_por)
glimpse(math_por)

```

*** =sct
```{r}

test_function("inner_join", args = c("x","y","by", "suffix"), incorrect_msg = "Please define the 'by' and 'suffix' arguments of `inner_join()` as instructed.")
test_object("math_por", incorrect_msg = "Please use `inner_join()` as instructed to create the object 'math_por'")

test_output_contains("colnames(math_por)", incorrect_msg = "Please print out the column names of the joined data")
test_function("glimpse", incorrect_msg = "Please use `glimpse()` on `math_por` to look at the data.")

test_error()
success_msg("Awsomeland! Imagine the possibilities of joining various data sets!")

```


--- type:NormalExercise lang:r xp:100 skills:1 key:fe19bbaae6
## Transforming by looping

You now have a data set which -- in addition to the background variables used for joining -- contains two (possibly different) answers to the same questions for each student. To fix this, you'll use programming to combine these 'duplicated' questions by either 

- taking the rounded average value of the two answers (for numeric variables)
- simply choosing the first answer (for factor variables).

You'll do this by using a combination of a `for-loop` and an `if-else` structure. The `if()` function takes a single logical condition as an argument and performs an action only if the condition is true. `if()` can then be combined with `else`, which handles the cases where the condition is false.

```
if(condition) {
   do something
} else {
   do something else
}

```

*** =instructions
- Create the object `notjoined_columns`
- Adjust the code: Create the data.frame `alc` by selecting only the columns in `math_por` which were used for joining the two questinaires. The names of those columns are available in the `join_by` object.
- Execute the for loop and then take a `glimpse()` at the 'alc' data.frame. The factor type variables should look strange at this point.
- Adjust the code inside the `for-loop`: if the first of the two selected columns is not numeric, add the first column to the `alc` data.frame.
-  Execute the `for-loop` and `glimpse()` at the new data again.

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(dplyr)
math <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-mat.csv",sep=";",header=TRUE)
por <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-por.csv",sep=";",header=TRUE)
join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
math_por <- inner_join(math, por, by = join_by, suffix = c(".math", ".por"))
```

*** =sample_code
```{r}
# dplyr, math_por, join_by are available

# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]

# create a new data frame with only the joined columns
alc <- select(math_por, one_of("change me!"))

# combine the 'duplicate' columns and add them to the 'alc' data frame
for(column_name in notjoined_columns) {
  # select the two columns with the same original name
  two_columns <- select(math_por, starts_with(column_name))
  first_column <- select(two_columns, 1)[[1]]

    # if the first column is numeric, take a rounded average
  if(is.numeric(first_column)) {
    alc[column_name] <- round(rowMeans(two_columns))
  } else { # else just use the first column
    alc[column_name] <- "change me!"
  }
}

# glimpse at the new combined data

```

*** =solution
```{r}
# dplyr, math_por, join_by are available

# columns that were not used for joining the data
notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]

# create a new data frame with only the joined columns
alc <- select(math_por, one_of(join_by))

# combine the 'duplicate' columns and add them to the 'alc' data frame
for(column_name in notjoined_columns) {
  # select the two columns with the same original name
  two_columns <- select(math_por, starts_with(column_name))
  first_column <- select(two_columns, 1)[[1]]

    # if the first column is numeric, take a rounded average
  if(is.numeric(first_column)) {
    alc[column_name] <- round(rowMeans(two_columns))
  } else { # else just use the first column
    alc[column_name] <- first_column
  }
}

# glimpse at the new combined data
glimpse(alc)

```

*** =sct
```{r}

test_object("alc", incorrect_msg = "Please follow the instructions to modify the `alc` data frame.")
test_function("glimpse", args = "x", incorrect_msg = "Please use `glimpse()` to look at the `alc` data.frame")
 
test_error()
success_msg("Good work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:ba34cfe7bd
## Mutations

Mutating the data means adding new variables, which are mutations of the existing ones. The `mutate()` function is from the 'dplyr' package. On your personal computer, instead of accessing the 'dplyr' package, you can install and access the 'tidyverse' package. The tidyverse includes several packages that work well together, such as 'dplyr' and 'ggplot2'.

The tidyverse functions have a lot of similarities. For example, the first argument of the tidyverse functions is usually 'data'. They also have other consistent features which makes them work well together and easy to use.

*** =instructions
- Mutate `alc` by creating the new column `alc_use` by averaging weekday and weekend alcohold consumption.
- Draw a bar plot of `alc_use`.
- Define a new asthetic element to the bar plot of `alc_use` by defining `fill = sex`. Draw the plot again.
- Mutate `alc` by creating a new logical variable `high_use`, which is true if `alc_use` is greater than 2 (adjust the code and replace `Inf`).
- Draw a bar plot of `high_use`.
- Add this element to the latter plot (using `+`): `facet_wrap("sex")`. Draw the plot again.

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(dplyr)
math <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-mat.csv",sep=";",header=TRUE)
por <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/student-por.csv",sep=";",header=TRUE)

join_by <- c("school","sex","age","address","famsize","Pstatus","Medu","Fedu","Mjob","Fjob","reason","nursery","internet")
math_por <- inner_join(math, por, by = join_by, suffix = c(".math", ".por"))

notjoined_columns <- colnames(math)[!colnames(math) %in% join_by]
alc <- select(math_por, one_of(join_by))

for(column_name in notjoined_columns) {
  # select the two columns with the same original name
  two_columns <- select(math_por, starts_with(column_name))
  first_column <- select(two_columns, 1)[[1]]

    # if the first column is numeric, take a rounded average
  if(is.numeric(first_column)) {
    alc[column_name] <- round(rowMeans(two_columns))
  } else { # else just use the first column
    alc[column_name] <- first_column
  }
}

library(ggplot2)
```

*** =sample_code
```{r}
# alc is available

# access the 'tidyverse' packages dplyr and ggplot2
library(dplyr); library(ggplot2)

# combine weekday and weekend alcohol use into 'alc_use'
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)

# initialize a  plot of 'alc_use'
g1 <- ggplot(data = alc, aes(alc_use, fill = sex))

# define the plot as a bar plot and draw it
g1 + geom_bar()

# transform alc_use into a binary variable 'high_use'
alc <- mutate(alc, high_use = Inf > 2)

# initialize a plot of 'high_use'
g2 <- ggplot(data = alc, aes(high_use))



```

*** =solution
```{r}
# alc is available

# access the 'tidyverse' packages dplyr and ggplot2
library(dplyr); library(ggplot2)

# combine weekday and weekend alcohol use into 'alc_use'
alc <- mutate(alc, alc_use = (Dalc + Walc) / 2)

# initialize a  plot of 'alc_use'
g1 <- ggplot(data = alc, aes(alc_use, fill = sex))

# define the plot as a bar plot and draw it
g1 + geom_bar()

# transform alc_use into a binary variable 'high_use'
alc <- mutate(alc, high_use = alc_use > 2)

# initialize a plot of 'high_use'
g2 <- ggplot(alc, aes(high_use))

# draw a bar plot for each sex
g2 + facet_wrap("sex") + geom_bar()


```

*** =sct
```{r}

test_object("alc", incorrect_msg = "Please mutate alc by creating a logical column 'high_use'.")
test_function("facet_wrap", args = "facets",incorrect_msg = "Please add the `facet_wrap('sex')` element to the latter bar plot.")

test_error()
success_msg("Very nice work! You're really getting the hang of it :)")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:6f326bbb98
## So many plots

I imagine you're curious to find out how the distributions of some of the other variables in the data look like. Well, why don't we visualize all of them! You'll also meet another new tidyverse toy, the pipe-operator: `%>%. 

The pipe (`%>%`) takes the result produced on it's left side and uses it as the first argument in the function on it's right side. Since the first argument of the tidyverse functions is usually 'data', this allows for some cool chaining of commands.

You'll look at `%>%` more closely in the next exercise. But now, let's draw some plots.

*** =instructions
- Access the tidyverse libraries tidyr, dplyr and ggplot2
- Take a glimpse at the `alc` data
- Take a glimpse at the `alc` data after applying the `gather()` function on it. What does gather do?
- Draw a bar plot of each variable in the `alc` data
- See the help page of the `options()` function and search for information about the 'warn' argument. Set the value of the argument so that warnings are never displayed.
- Draw the plots again.

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
```

*** =sample_code
```{r}
# alc is available

# access the tidyverse libraries tidyr, dplyr, ggplot2
library(tidyr); library(dplyr); library(ggplot2)

# use options() to ignore warnings


# use gather() to gather columns into key value pairs 
glimpse(gather(alc))

# draw a bar plot of each variable
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()


```

*** =solution
```{r}
# alc is available

# access the tidyverse libraries tidyr, dplyr, ggplot2
library(tidyr); library(dplyr); library(ggplot2)

# glimpse at the alc data
glimpse(alc) 

# use options() to ignore warnings
options(warn = -1)

# gather() gathers all columns into key-value pairs 
glimpse(gather(alc))

# draw a bar plot of each variable
gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()


```

*** =sct
```{r}

test_function("options", eval = F, args = "warn", incorrect_msg = "Please use the `options()` function to modify whether warnings are displayed.")

# test_error()
success_msg("Great job!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:0f61649b52
## The Pipe: summarising by group

The pipe operator, `%>%`, takes the result of the left-hand side and uses it as the first argument of the function on the right-hand side. For example:

```
1:10 %>% mean()
[1] 5.5

```
The pipe is most commonly used to chain functions which perform operations on a data.frame. Chaining operations with the pipe is great fun, so let's try it! 

Utilizing the pipe, you'll apply the functions `group_by()` and `summarise()` on your data. The first one splits the data to groups according to a grouping variable (a factor, for example), and the latter can be combined with any summary function such as `mean()`, `min()`, `max()` or `sd()` to summarize the data. 

*** =instructions
- Access the tidyverse libraries dplyr and ggplot2
- Execute the sample code to see the counts of males and females in the data
- Adjust the code: inside `summary()` define 'mean_grade' by using `mean()` on the variable `G3`, which is the average final grade of math and portuguese. Execute the code again.
- Adust the code: After sex, add 'high_use' as another grouping variable and execute the code again.

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
```

*** =sample_code
```{r}
# alc is available

# access the tidyverse libraries dplyr and ggplot2
library(dplyr); library(ggplot2)

# produce summary statistics by group
alc %>% group_by(sex) %>% summarise(count = n(), mean_grade = "change me!")


```

*** =solution
```{r}
# alc is available

# access the tidyverse libraries dplyr and ggplot2
library(dplyr); library(ggplot2)

# produce summary statistics by group
alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))


```

*** =sct
```{r}

test_output_contains("alc %>% group_by(sex, high_use) %>% summarise(count = n(), mean_grade = mean(G3))", incorrect_msg = "Please make the requested changes to the arguments of the `group_by()` and `summarise()` functions.")
 test_error()
success_msg("Very nice work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:e11583db2a
## Box plots by groups

Box plots are an excellent way of displaying and comparing distributions. A box plot visualizes the 25th, 50th and 75th percentiles (the box), the typical range (the whiskers) and the outliers of a variable. 

The whiskers extending from the box can be computed by several techniques. The default (in base R and ggplot) is to extend them to reach to a data point that is no more than 1.5*IQR away from the box, where IQR is the inter quartile range defined as  

`IQR = 75th percentile - 25th percentile`  

Values outside the whiskers can be considered as outliers, unusually distant observations. For more information on IQR, see <a target="_blank" href ="https://en.wikipedia.org/wiki/Interquartile_range"> wikipedia</a>

*** =instructions
- Initialize and draw a box plot of student grades ('G3'), grouped by 'high_use'.
- Add an aesthetix element to the plot by defining `col = sex` inside `aes()`
- Add the element `ylab("grade")` to the plot.
- Define a similar (box) plot of the variable 'absences' again grouped by 'high_use' and the aesthetic `col=sex`.
- Add a main title to the last plot with `ggtitle("title here")`. Insert the title "Student absences by alcohol consumption and sex".

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
```

*** =sample_code
```{r}
library(ggplot2)

# initialize a plot of 'high_use' and 'G3'
g1 <- ggplot(alc, aes(x = high_use, y = G3))

# define the plot as a boxplot and draw it
g1 + geom_boxplot()

# initialise a plot of high_use and 'absences'


# define the plot as a boxplot and draw it


```

*** =solution
```{r}
library(ggplot2)

# initialize a plot of 'high_use' and 'G3'
g1 <- ggplot(alc, aes(x = high_use, y = G3, col = sex))

# define the plot as a boxplot and draw it
g1 + geom_boxplot() + ylab("grade")

# initialise a plot of high_use and 'absences'
g2 <- ggplot(alc, aes(x = high_use, y = absences, col = sex))

# define the plot as a boxplot and draw it
g2 + geom_boxplot() + ggtitle("Student absences by alcohol consumption and sex")

```

*** =sct
```{r}

test_function("ylab", args = "label",incorrect_msg = "Please define the aesthetic element col = sex to the first box plot and then adjust the label of the y axis with `ylab()`")

test_function("ggtitle", args = "label", incorrect_msg = "Please define box plots of the 'absences' variable with the appropriate grouping and then adjust the main title with `ggtitle()` as instructed")

test_error()
success_msg("Great work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:9d4b84e1b0
## Learning a logistic regression model

We will now use logistic regression to identify factors related to higher than average student alcohol consumption. You will also attempt to learn to identify (predict) students who consume high amounts of alchohol using background variables and school performance.


*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
```

*** =sample_code
```{r}
# alc is available 

# find the model with glm()
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

## print out the coefficients
m

## print out the exponentiated coefficients
exp(coefficients(m))
```

*** =solution
```{r}
# alc is available

# find the model with glm()
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# print out a summary of the model
summary(m)

## print out the coefficients
m

## print out the exponentiated coefficients
exp(coefficients(m))
```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1
## Model performance: prediction accuracy

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
library(dplyr)
```

*** =sample_code
```{r}
# alc, dplyr are available

# fit the model
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# using the model, predict() the probability of the target variable
alc <- mutate(alc, probability = predict(m, type = "response"))

# Use the probabilities to make a class prediction
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins

```

*** =solution
```{r}
# alc, dplyr are available

# fit the model
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# using the model, predict() the probability of the target variable
alc <- mutate(alc, probability = predict(m, type = "response"))

# Use the probabilities to make a class prediction
alc <- mutate(alc, prediction = probability > 0.5)

# tabulate the target variable versus the predictions
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table %>% addmargins



```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1
## The ROC curve

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)
```

*** =sample_code
```{r}

# alc is available

# fit the model
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# using the model, predict() the target variable
alc <- mutate(alc, probability = predict(m, type = "response"))
alc <- mutate(alc, prediction = probability > 0.5)

# draw a roc curve and and compute the area under the curve (auc)
library(pROC)
r <- roc(high_use ~ probability, data = alc)
plot(r)

```

*** =solution
```{r}
# alc is available

# fit the model
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")

# predict() the probability of the target variable
alc <- mutate(alc, probability = predict(m, type = "response"))

# draw a roc curve and and compute the area under the curve (auc)
library(pROC)
r <- roc(high_use ~ probability, data = alc)
plot(r)
```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```


--- type:NormalExercise lang:r xp:100 skills:1
## Model performance: cross-validation

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
alc <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_3140/datasets/alc.txt", sep  =",", header = T)

# fit the model
m <- glm(high_use ~ sex + failures + absences, data = alc, family = "binomial")
# predict() the probability of the target variable
alc <- mutate(alc, probability = predict(m, type = "response"))
```

*** =sample_code
```{r}
# m and alc with prediction probabilities are available

# loss function
loss_func <- function(class, probability) mean(abs(class - probability) > 0.5)

# average number of wrong predictions in the (training) data
loss_func(alc$high_use, alc$probability)

# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = cost_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```

*** =solution
```{r}
# m and alc with prediction probabilities are available

# loss function
loss_func <- function(class, probability) mean(abs(class - probability) > 0.5)

# average number of wrong predictions in the (training) data
loss_func(alc$high_use, alc$probability)

# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc, cost = loss_func, glmfit = m, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

