---
title       : Clustering and classification
description : K-means clustering, Discriminant analysis

--- type:NormalExercise lang:r xp:100 skills:1 key:3db2d48f25
## Datasets inside R

Welcome to the *Clustering and classification* chapter.

R has many (usually small) datasets already loaded in. There are also datasets included in the package installations. Some of the datasets are quite famous (like the [Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) flower data) and they are frequently used for teaching purposes or to demonstrate statistical methods. 

This week we will be using the [Boston](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html) dataset from the MASS package. Let's see how it looks like!


*** =instructions
- Load the `Boston` dataset from MASS
- Explore the `Boston` dataset. Look at the structure with `str()` and use `summary()` to see the details of the variables.
- Draw the plot matrix with `ggpairs()`
- Change the plot so that density plots are in the upper side of the matrix and scatter plots are in the lower side of the matrix

*** =hint
- You can draw the `ggpairs()` plot by typing the object name where it is saved.

*** =pre_exercise_code
```{r}

```

*** =sample_code
```{r}
# access the MASS package
library(MASS)

# load the data
data("Boston")

# explore the dataset
str(Boston)
summary(Boston)

# plot matrix of the variables
library(GGally)
library(ggplot2)
p <- ggpairs(Boston, mapping = aes(), upper = list(continuous = wrap("cor"), alpha = 0.3), lower = list(continuous = wrap("points")), alpha = 0.6)

# draw the plot


```

*** =solution
```{r}
# access the MASS package
library(MASS)

# load the data
data("Boston")

# explore the dataset
str(Boston)
summary(Boston)

# plot matrix of the variables
library(GGally)
library(ggplot2)
p <- ggpairs(Boston, mapping = aes(), upper = list(continuous = wrap("points")), lower = list(combo = wrap("facethist", bins=10)))

# draw the plot
p

```

*** =sct
```{r}
test_output_contains("summary(Boston)", incorrect_msg = "Did you use the summary() function on the Boston data?")

test_output_contains("str(Boston)", incorrect_msg = "Did you use the str() function on the Boston data?")

test_student_typed("p", not_typed_msg = "Please draw the plot created with `ggpairs()`")

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:603dff42ce
## Correlations plot

The `ggpairs()` function plots the correlations numbers in the plot matrix quite nicely (if the argument `cor` is chosen). A more visual way to see the correlations quickly is to use `corrplot()` function (from the corrplot package).

It is useful to The 

*** =instructions
- Calculate the correlation matrix and save it as `cor_matrix`. Print the matrix to see how it looks like.
- Adjust the code: use the pipe (`%>%`) to round the matrix. Rounding can be done with the `round()` function. Use the first two digits. Print the matrix again. 
- Plot the rounded correlation matrix
- Adjust the code: add argument `type="upper"` to the plot. Print the plot again. 
- Adjust the code little more: add arguments `cl.pos="b"`, `tl.pos="d"` and `tl.cex = 0.6` to the plot. Print the plot again. 
- See more of corrplot [here](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html)

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(MASS)
library(corrplot)
library(tidyverse)

data("Boston")

```

*** =sample_code
```{r}
# MASS and Boston dataset are available

# access corrplot and tidyverse packages
library(corrplot)
library(tidyverse)

# calculate the correlation matrix
cor_matrix<-cor(Boston) %>% round(digits = 2)

# print the correlation matrix
cor_matrix

# visualize the correlation matrix
corrplot(cor_matrix, method="circle")

```

*** =solution
```{r}
# MASS and Boston dataset are available

# access corrplot and tidyverse packages
library(corrplot)
library(tidyverse)

# calculate the correlation matrix
cor_matrix<-cor(Boston) %>% round(digits = 2)

# visualize the correlation matrix
corrplot(cor_matrix, method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex = 0.6)

```

*** =sct
```{r}

test_function("round", args = "digits",incorrect_msg = "Did you use the first two digits in rounding?")
# test_function("corrplot", args = "type",incorrect_msg = "Did you set the `type` to upper in corrplot?")
# test_function("corrplot", args = "type",incorrect_msg = "Did you set the `cl.pos` in corrplot?")
# test_function("corrplot", args = "cl.pos",incorrect_msg = "Did you set the `cl.pos` in corrplot?")
# test_function("corrplot", args = "cl.pos",incorrect_msg = "Did you set the `cl.pos` in corrplot?")

test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:3a4eacf66c
## Scale the whole dataset

Usually the R datasets do not need much data wrangling as they are already in a good shape. 

For later use, we will need to scale the data. The Boston data contains only numerical values, so we can use the function `scale()` to standardize the dataset.

*** =instructions
- Use the `scale()` function on the `Boston` dataset. Save the scaled data to `boston_scaled` object.
- Use `summary()` to look at the scaled variables. Note the means of the variables.
- Find out the class of the scaled object by executing the `class()` function. 
- Later we will want the data to be a data frame. Use `as.data.frame()` to convert the `boston_scaled` to a data frame format. Keep the object name as `boston_scaled`.

*** =hint
- `?scale`

*** =pre_exercise_code
```{r}
library(MASS)
library(corrplot)
library(tidyverse)

data("Boston")
```

*** =sample_code
```{r}
# MASS and Boston dataset are available

# center and standardize variables


# summaries of the scaled variables


# class of the boston_scaled object
class(boston_scaled)

# change the object to data frame


```

*** =solution
```{r}
# MASS and Boston dataset are available

# center and standardize variables
boston_scaled <- scale(Boston)

# summaries of the scaled variables
summary(boston_scaled)

# class of the boston_scaled object
class(boston_scaled)

# change the object to data frame
boston_scaled <- as.data.frame(boston_scaled)

```

*** =sct
```{r}
test_function("scale", args = "x",incorrect_msg = "Did you scale the dataset?")

test_function("as.data.frame", args = "x",incorrect_msg = "Please use the function as.data.frame() to convert the data to a data frame.")

test_function("summary", args = "object", incorrect_msg = "Please use the function summary() to look at the summaries of the data variables.")

test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:3d45bd1da6
## Creating a target variable

We will need a categorical variable as a target in the linear discriminant analysis in the next exercise. The scaled Boston dataset contains only continious variables, so we will need to create one. See how it's done below!

*** =instructions
- Let's choose the variable `crim` (per capita crime rate by town) to be our target. The description of the Boston dataset variables could be seen [here](https://stat.ethz.ch/R-manual/R-devel/library/MASS/html/Boston.html).
- Look at the summary of the (scaled) variable `crim`
- We want to cut the variable by [quantiles](https://en.wikipedia.org/wiki/Quantile). Use the function `quantile()` on the scaled crime rate variable and save the results to `bins`. Print the results.
- Create categorical crime vector with the `cut()` function. Set the `breaks` argument to be the quantile vector you just created. Print the results.
- Create a string vector from `"low"`, `"med_low"`, `"med_high"`, `"high"` (in that order) and save it as `label_names`.
- Adjust the code of `cut()` by adding the `label` argument in the function. Set the `label_names` as labels and print the categorical variable again.
- Execute the last lines of code to remove the original crime rate variable and adding the new one to scaled Boston dataset. 

*** =hint
- 

*** =pre_exercise_code
```{r}
library(MASS)
data("Boston")
boston_scaled <- as.data.frame(scale(Boston))
```

*** =sample_code
```{r}
# MASS, Boston and boston_scaled are available

# summary of the scaled crime rate


# create a quantile vector of crim and print it
bins <- "change me!"


# create a categorical variable 'crime' and print it
crime <- cut(boston_scaled$crim, breaks = "change me!", include.lowest = TRUE)


# label names
label_names <- "change me!"

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

```

*** =solution
```{r}
# MASS, Boston and boston_scaled are available

# summary of the scaled crime rate
summary(boston_scaled$crim)

# create a quantile vector of crim and print it
bins <- quantile(boston_scaled$crim)
bins

# create a categorical variable 'crime' and print it
crime <- cut(boston_scaled$crim, breaks=bins, include.lowest = TRUE, labels = label_names)
crime 

# label names
label_names <- c("low", "med_low", "med_high", "high")

# remove original crim from the dataset
boston_scaled <- dplyr::select(boston_scaled, -crim)

# add the new categorical value to scaled data
boston_scaled <- data.frame(boston_scaled, crime)

```

*** =sct
```{r}
test_function("summary", args = "object", incorrect_msg = "Please use the function summary() on crime rate.")

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 

test_error()
success_msg("Nicely done! By the way, sometimes there are functions with the same name in different R packages (like `select` in **dplyr** and **MASS**). You can choose which one to use by adding the name of the package with two colons in front of the function call (for example `dplyr::select()`).")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:2de2d66d11
## Linear Discriminant analysis(1)

[Linear Discriminant analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis) is a classification (and dimension reduction) method. It finds the (linear) combination of the features that separate the target variable classes. The target can be binary or multiclass variable. 

Linear discriminant analysis is closely related to many other methods, such as principal component analysis (we will look into that next week) and the already familiar logistic regression. 

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(MASS)
boston_scaled <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/boston_scaled.txt", sep  =",", header = T)
```

*** =sample_code
```{r}
# http://stackoverflow.com/questions/17232251/how-can-i-plot-a-biplot-for-lda-in-r
lda.arrows <- function(x, myscale = 1, color='red', tex = 0.75, choices = c(1,2), ...){
  ## adds `biplot` arrows to an lda using the discriminant function values
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, ...)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

lda.fit = lda(crime ~ ., data=boston_scaled)
plot(lda.fit, col=as.numeric(boston_scaled$crime), pch=as.numeric(boston_scaled$crime))
lda.fit
pred.lda <- predict(lda.fit, boston_scaled)

pred.lda$x
table(boston_scaled$crime, pred.lda$class)

df <- dplyr::select(boston,-crime)
dim(df)
dim(lda.fit$scaling)

MM <- as.matrix(df) %*% lda.fit$scaling
MM <- as.data.frame(MM)
plot(MM, col=as.numeric(boston$crime), pch=as.numeric(boston$crime))
lda.arrows(lda.fit, myscale = 1)


```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```
--- type:NormalExercise lang:r xp:100 skills:1 key:50338b95ba
## Linear Discriminant analysis(2)

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}

```

*** =sample_code
```{r}

```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:10414fc9d1
## More dimensions with Plotly!

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}
# access the MASS package
library(MASS)

# load the data
data("Boston")

# center and standardize variables
boston <- as.data.frame(scale(Boston))

# crim to categorical
summary(boston$crim)
crime <- cut(boston$crim, quantile(boston$crim), include.lowest = TRUE, 
             labels = c("low", "med_low", "med_high", "high"))

# remove original
boston <- dplyr::select(boston, -crim)

# combine
boston <- data.frame(boston, crime)

lda.fit = lda(crime ~ ., data=boston)
df <- dplyr::select(boston,-crime)
MM <- as.matrix(df) %*% lda.fit$scaling
```

*** =sample_code
```{r}
# 3D plot
library(plotly)

d <- as.data.frame(MM)
plot_ly(data=d, x = d$LD1, y = d$LD2, z = d$LD3, color=crime,
        type= 'scatter3d', mode='markers')

```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:6719c6079e
## Distance measures

Similarity or dissimilarity of objects can be measured with distance measures. There are many different measures for different types of data. The most common or "normal" distance measure is [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance). 

There are functions that calculate the distances in R. In this exercise, we will be using the base R's `dist()` function. The function creates a distance matrix that is saved as dist object. The distance matrix is usually square matrix containing the pairwise distances of the observations. So with large datasets, the computation of distance matrix is time consuming and storing the matrix might take a lot of memory. 

*** =instructions
- Load the MASS package and the `Boston` dataset from it
- Create `dist_eu` by calling the `dist()` function on the Boston dataset. Note that by default, the function uses Euclidean distance measure.
- Look at the head of the `dist_eu`
- Next create object `dist_man` that contains the Manhattan distance matrix of the Boston dataset
- Look at the first six values of the `dist_man`

*** =hint
- `data(*name_of_the_dataset*)` can be used to load dataset from R package
- Look at the help page of `dist()` function with `?dist`

*** =pre_exercise_code
```{r}
library(MASS)
data('Boston')
```

*** =sample_code
```{r}
# load MASS and Boston
library(MASS)
data('Boston')

# euclidean distance matrix
dist_eu <- "change me!"

# look at the first 6 distances


# manhattan distance matrix
dist_man <- "change me!"

# look at the first 6 distances
head(dist_man)

```

*** =solution
```{r}
# load MASS and Boston
library(MASS)
data('Boston')

# euclidean distance matrix
dist_eu <- dist(Boston)

# look at the first 6 distances
head(dist_eu)

# manhattan distance matrix
dist_man <- dist(Boston, method = 'manhattan')

# look at the first 6 distances
head(dist_man)

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```


--- type:NormalExercise lang:r xp:100 skills:1 key:f3d6cd6c00
## K-means (1)

[K-means](https://en.wikipedia.org/wiki/K-means_clustering) is maybe the most used and known clustering method. It is an unsupervised method, that assigns observations to groups or **clusters** based on similarity of the objects.

K-means needs the number of clusters as an argument. One way to determine the number of clusters is to look at the within sum of squares that the clustering produces. 

*** =instructions
- Execute the code for the distance matrix
- Set the max number of clusters (`k_max`) to be 10.
- Execute the code to calculate within sum of squares. This might take a while.
- Visualize the within sum of squares when the number of cluster goes from 1 to 10. The optimal number of clusters is when the value of within sum of squares changes radically. 

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(MASS)
library(ggplot2)

data('Boston')
set.seed(123)
```

*** =sample_code
```{r}
# MASS, ggplot2 and Boston dataset are available

# euclidean distance matrix
dist_eu <- dist(Boston)

# determine the number of clusters
k_max <- "change me!"

# calculate within sum of square
wss <- sapply(1:k_max, function(k){kmeans(dist_eu, k, nstart=10)$tot.withinss})

# visualize WSS
qplot(x = 1:k_max, y = wss, geom = 'line', main = 'Elbow method')

```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Well done! ")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:63da6251d5
## K-means (2)

Now based on the Elbow plot we drew in the last exercise we can choose the number of clusters. Let's see how the clusters will look like. 

*** =instructions
- Based on the 

*** =hint
- hint

*** =pre_exercise_code
```{r}
library(MASS)
library(ggplot2)

data('Boston')
set.seed(13)
dist_eu <- dist(Boston)
```

*** =sample_code
```{r}
# Boston and dist_eu are available
km <-kmeans(dist_eu, "change me!")

# plot the pairwise 
pairs(Boston)
```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Clustering like a pro!")
```

--- type:NormalExercise lang:r xp:100 skills:1 key:0b27c3c46a
## K-medoids

Exercise info here

*** =instructions
- instruction

*** =hint
- hint

*** =pre_exercise_code
```{r}

```

*** =sample_code
```{r}
library(cluster)
pa <- pam(dist(df), 3)
# pairs(df, col=pa$cluster)
plot_ly(data=d, x=d$LD1, y=d$LD2, z=d$LD3, color=pa$cluster,
        type= 'scatter3d', mode='markers')
```

*** =solution
```{r}

```

*** =sct
```{r}

# test_function("", args = "",incorrect_msg = "")
# test_object("", incorrect_msg = "")
# test_output_contains("", incorrect_msg = "")
# 
# test_error()
success_msg("Good work!")
```

